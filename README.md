# Analysing-a-Time-Series-dataset-with-many-models-and-data-classification-using-Logistic-Regression
This project presents the results of two separate analyses: a time series analysis of monthly and yearly average temperatures in Armagh from 1844 to 2004, and a binary logistic regression analysis of a dataset containing details of blood samples of diabetic patients collected in an Iraqi University Hospital in 2020. The time series analysis provides insights into historical temperature variation patterns in Armagh and can inform future climate projections for the region. The logistic regression analysis facilitates diabetes diagnosis based on blood results and has implications for diabetes diagnosis and treatment in clinical settings. The two analyses detail the process of constructing the model, give an overview of the ultimate model parameters, assess pertinent assumptions, and evaluate the performance and fitness of the model.
# WorkFlow
PART A: Time Series Analyses
1. Assessment of Raw Time Series: The two datasets were visually explored using R programming language. The monthly average temperature dataset ”nitm18442004.csv” contains 1932 observations of the average temperature in Armagh from January 1844 to De- cember 2004, while the yearly average temperature dataset ”nity18442004.csv” contains 161 observations of the yearly average temperature from 1844 to 2004. The monthly aver- age temperature dataset exhibited a distinct seasonal pattern, with higher temperatures in the summer months and lower temperatures in the winter months. This pattern is typical of temperature data in temperate regions.
2. Investigation of Suitable models: In this section, different suitable time series models for both monthly and yearly temperature data were explored using the following categories: i. Exponential Smoothing ii. ARIMA/SARIMA iii. Simple time series models.
(i) Exponential Smoothing: This is a popular forecasting method for univariate time series data that can be applied to monthly and yearly temperature data. Exponentially declining weights are used in exponential smoothing models to predict future values using prior data as a weighted average. It can be fit with different models. Here, the ETS function has been used to automatically aid in choosing the best model to match the data because it has more options and it is generally more powerful. The model summary includes the ETS (Error, Trend, Seasonality) which consists of ETS(A,A,A) and ETS(A,N,N).
(ii) ARIMA/SARIMA: The Arima model was also explored. To apply this approach, we first evaluated the ”ndiffs()” function’s output for our degree of freedom, which gave us d=1. To make the differenced temperature time series stationary, we also produced a plot of it. The Augmented Dickey-Fuller Test (adf.test(ts)) was run to further support this assertion, and the outcomes demonstrated its stationarity. Finding the ARIMA models that match the data the best is done using the Auto- ARIMA function.
(iii) Time Series Models: For the Time series model, Mean and Naive forecast was used. i. Average or Mean Method: This approach adheres to the principle that all future values must equal the average of past data. The mean(train) for the monthly data is 8.494 and for the yearly data is 8.4825. ii. Naive or Random Walk Method: Typically, the forecast for this approach is configured to reflect the value of the most recent observation. For the yearly data, the train[length(train)] is 9.3, whereas it is 5.1 for the monthly data.
3. Forecasting and assessment of the adequacy of the final model: Evaluation of the forecast of monthly and yearly tempera- ture against the actual of data of 2004 was also assessed. different metrics were used such as RMSE,
